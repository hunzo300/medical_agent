import autorootcwd
import torch.nn as nn
import matplotlib.pyplot as plt
import torch
import numpy as np
import os
import copy
from segment_anything_CoMed import sam_model_registry
import torch.nn.functional as F
from torch.utils.data import DataLoader
from IVDM3Seg.train.train import NpyDataset, CoMedSAM, show_mask, show_box, args, join
import glob

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


# Dice Score ê³„ì‚° í•¨ìˆ˜
def calculate_dice_score(pred, target, epsilon=1e-6):
    pred = pred.flatten()
    target = target.flatten()
    
    intersection = (pred * target).sum()
    dice = (2. * intersection + epsilon) / (pred.sum() + target.sum() + epsilon)
    
    return dice

def inference_on_npy(data_root, file_prefix, bbox_shift=0):
    """
    :param data_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
    :param file_prefix: ì²˜ë¦¬í•  íŒŒì¼ì˜ prefix (ì˜ˆ: "15-12")
    """
    # âœ… í•´ë‹¹ prefixë¥¼ í¬í•¨í•˜ëŠ” ëª¨ë“  npy íŒŒì¼ ê²€ìƒ‰
    matching_files = sorted(glob.glob(os.path.join(data_root, "gts", f"{file_prefix}_*.npy")))

    if not matching_files:
        print(f"No matching files found for prefix: {file_prefix}")
        return

    # âœ… ëª¨ë¸ ë¡œë”©
    sam_model = sam_model_registry["vit_b"](checkpoint="/home/minkyukim/mm-sam_tutorial/work_dir/SAM/sam_vit_b_01ec64.pth")

    def create_image_encoder():
        return copy.deepcopy(sam_model.image_encoder).to(device)

    mm_sam = CoMedSAM(
        image_encoder_factory=create_image_encoder,
        mask_decoder=sam_model.mask_decoder.to(device),  
        prompt_encoder=sam_model.prompt_encoder.to(device), 
        indicator=[1, 1, 1, 1]
    ).to(device)

    checkpoint_path = "/mnt/sda/minkyukim/pth/revision/MM_ivdm_2way/MM_2.pth"
    checkpoint = torch.load(checkpoint_path)

    mm_sam.load_state_dict(checkpoint, strict=False)
    mm_sam.eval()

    all_input_images = []
    all_gt_masks = []
    all_predicted_masks = []

    for npy_file in matching_files:
        dataset = NpyDataset(data_root, bbox_shift=bbox_shift)
        dataset.gt_path_files = [npy_file]
        
        dataloader = DataLoader(dataset, batch_size=1, shuffle=False)

        for step, (images, gt, bboxes, img_names) in enumerate(dataloader):
            images = images.to(device)
            gt = gt.to(device)

            with torch.no_grad():
                pred_mask = mm_sam(images, bboxes.cpu().numpy())

            # Resizing GT and predicted masks
            gt_resized = F.interpolate(gt.float(), size=(1024, 1024), mode='nearest').squeeze(1)
            gt_mask_np = np.clip(gt_resized[0].cpu().numpy(), 0, 1)

            pred_mask_resized = F.interpolate(pred_mask.float(), size=(1024, 1024), mode='nearest').squeeze(0)
            pred_mask_np = np.clip(pred_mask_resized[0].cpu().numpy(), 0, 1)

            # âœ… GT ë° Predicted Mask ì €ì¥ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_gt_masks.append(gt_mask_np)
            all_predicted_masks.append(pred_mask_np)


            # ğŸ”¥ ì²« 4ê°œ Input Imageë§Œ ì €ì¥
            for i in range(min(images.shape[1], 4)):  
                if len(all_input_images) < 4:  # ì²« 4ê°œê¹Œì§€ë§Œ ì €ì¥
                    image_np = images[0, i].cpu().permute(1, 2, 0).numpy()
                    image_np = np.clip(image_np, 0, 1)
                    all_input_images.append(image_np)

            print(f"Inference completed for: {npy_file}")

    # âœ… GT Masks ë° Predicted Masksë¥¼ í•˜ë‚˜ë¡œ í•©ì‚°
    gt_final_mask = np.sum(all_gt_masks, axis=0)
    pred_final_mask = np.sum(all_predicted_masks, axis=0)
    pred_final_mask[pred_final_mask > 1] = pred_final_mask[pred_final_mask > 1] // 2

    # âœ… Dice Score ê³„ì‚° (ìµœì¢… GTì™€ ìµœì¢… ì˜ˆì¸¡ ê°’ ë¹„êµ)
    final_dice_score = calculate_dice_score(torch.tensor(pred_final_mask), torch.tensor(gt_final_mask))
    dice_score_str = f"{final_dice_score:.4f}"

    # âœ… í´ë” ìƒì„± (í´ë”ëª…ì— Dice Score ì¶”ê°€)
    output_folder = f"ablation_images/{file_prefix}_dice_{dice_score_str}"
    os.makedirs(output_folder, exist_ok=True)

    # âœ… Input Image 4ê°œ ê°œë³„ ì €ì¥
    for i, img in enumerate(all_input_images):
        plt.imsave(f"{output_folder}/input_{i+1}.png", img)

    # âœ… ìµœì¢… GT ë° Predicted Mask ì €ì¥
    plt.imsave(f"{output_folder}/gt_final.png", gt_final_mask, cmap='gray')
    plt.imsave(f"{output_folder}/predicted_final.png", pred_final_mask, cmap='gray')
    print(f"Saved Final GT Mask: {output_folder}/gt_final.png")
    print(f"Saved Final Predicted Mask: {output_folder}/predicted_final.png")

    # ğŸ”¥ ì˜¤ë²„ë ˆì´ ì‹œê°í™”: GT ê¸°ì¤€ìœ¼ë¡œ FP(íŒŒë€ìƒ‰), FN(ë¹¨ê°„ìƒ‰) í‘œì‹œ
    overlay = np.zeros((*gt_final_mask.shape, 3), dtype=np.uint8)

    false_positive = (pred_final_mask > 0) & (gt_final_mask == 0)  # FP: ìˆì–´ì•¼ í•  ê³³ì— ì—†ìŒ
    false_negative = (pred_final_mask == 0) & (gt_final_mask > 0)  # FN: ì—†ì–´ì•¼ í•  ê³³ì— ìˆìŒ

    overlay[false_positive] = [0, 0, 255]  # ğŸ”µ íŒŒë€ìƒ‰ (FP)
    overlay[false_negative] = [255, 0, 0]  # ğŸ”´ ë¹¨ê°„ìƒ‰ (FN)

    # âœ… Overlay ì €ì¥
    plt.imsave(f"{output_folder}/overlay.png", overlay)
    print(f"Saved Overlay Image: {output_folder}/overlay.png")

    # ğŸ”¥ `predicted_final.png` ìœ„ì— Overlayë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì ìš©í•œ ì´ë¯¸ì§€ ì €ì¥
    predicted_rgb = np.stack([pred_final_mask] * 3, axis=-1) * 255  # Grayscaleì„ RGBë¡œ ë³€í™˜

    # âœ… Overlayê°€ ìˆëŠ” í”½ì…€ì„ ìš°ì„ ìœ¼ë¡œ í‘œì‹œ (FP/FNì´ ìˆëŠ” ê³³ì€ Overlay ìƒ‰ìƒ ìœ ì§€)
    mask_overlay = (overlay > 0).any(axis=-1)  # FP/FNì´ ìˆëŠ” ë¶€ë¶„ ì°¾ê¸°
    predicted_rgb[mask_overlay] = overlay[mask_overlay]  # Overlay ì ìš©

    plt.imsave(f"{output_folder}/overlay_on_predicted.png", predicted_rgb/255.0)
    print(f"Saved Overlay on Predicted Image: {output_folder}/overlay_on_predicted.png")

# ì‹¤í–‰
data_root = "/mnt/sda/minkyukim/CoMed-sam_dataset/IVDM_/ivdm_npy_test_dataset_1024image"
file_prefix = "15-13"  # ğŸ”¥ Prefixë¥¼ ì…ë ¥í•˜ë©´ í•´ë‹¹í•˜ëŠ” ëª¨ë“  Phaseë¥¼ ìë™ìœ¼ë¡œ ì°¾ìŒ
inference_on_npy(data_root, file_prefix)